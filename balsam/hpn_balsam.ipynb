{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Python search path includes: ['/soft/datascience/Balsam/0.3.5.1/', \"\n",
      " \"'/soft/datascience/Balsam/0.3.5.1/env/lib/python3.6/site-packages/', \"\n",
      " \"'/opt/anaconda3/lib/python36.zip', '/opt/anaconda3/lib/python3.6', \"\n",
      " \"'/opt/anaconda3/lib/python3.6/lib-dynload', '', \"\n",
      " \"'/opt/anaconda3/lib/python3.6/site-packages', \"\n",
      " \"'/opt/anaconda3/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg', \"\n",
      " \"'/opt/anaconda3/lib/python3.6/site-packages/IPython/extensions', \"\n",
      " \"'/gpfs/mira-home/rvescovi/.ipython']\")\n"
     ]
    }
   ],
   "source": [
    "# The magic commands below allow reflecting the changes in an imported module without restarting the kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# We need to add balsam and the modules it depends on to the Python search paths. \n",
    "import sys\n",
    "sys.path.insert(0,'/soft/datascience/Balsam/0.3.5.1/env/lib/python3.6/site-packages/')\n",
    "sys.path.insert(0,'/soft/datascience/Balsam/0.3.5.1/')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(f'Python search path includes: {sys.path}')\n",
    "\n",
    "# We also need postgresql to be in the path\n",
    "import os\n",
    "os.environ['PATH'] ='/soft/datascience/Balsam/0.3.5.1/env/bin/:' + os.environ['PATH']\n",
    "os.environ['PATH'] +=':/soft/datascience/PostgreSQL/9.6.12/bin/'\n",
    "\n",
    "try:\n",
    "    import balsam\n",
    "except:\n",
    "    print('Cannot find balsam, make sure balsam is installed or it is available in Python search paths')    \n",
    "\n",
    "    # We also need to activate Balsam database by setting the BALSAM_DB_PATH environment variable. \n",
    "# This is equivalent to `source balsamactivate jupyter_test` \n",
    "os.environ[\"BALSAM_DB_PATH\"]='/lus/theta-fs0/projects/connectomics_aesp/balsam_database/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_paths(verbose=True):\n",
    "    \"\"\"\n",
    "    Prints the paths for existing balsam databases\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from balsam.django_config.db_index import refresh_db_index\n",
    "        databasepaths = refresh_db_index()\n",
    "    except:\n",
    "        databasepaths = None\n",
    "    if verbose:\n",
    "        if len(databasepaths) > 0:\n",
    "            print(f'Found {len(databasepaths)} balsam database location')\n",
    "            for db in databasepaths:\n",
    "                print(db)\n",
    "        else:\n",
    "            print('No balsam database found')\n",
    "    return databasepaths\n",
    "\n",
    "def get_active_database(verbose=True):\n",
    "    \"\"\"\n",
    "    Gets the activate database set in environment variable BALSAM_DB_PATH\n",
    "    Parameters:\n",
    "    verbose: Boolean, (True): Prints verbose info (False): No print\n",
    "    Returns\n",
    "    -------\n",
    "    str, path for the active database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db = os.environ[\"BALSAM_DB_PATH\"]\n",
    "        if verbose: print(f'Active balsam database path: {db}')\n",
    "    except:\n",
    "        if verbose: print('BALSAM_DB_PATH is not set')\n",
    "        db = None\n",
    "    return db\n",
    "    \n",
    "def add_app(name, executable, description='', envscript='', preprocess='', postprocess='', checkexe=False):\n",
    "    \"\"\"\n",
    "    Adds a new app to the balsam database.\n",
    "    \"\"\"\n",
    "    from balsam.core.models import ApplicationDefinition as App\n",
    "    import shutil\n",
    "    \n",
    "    if checkexe:\n",
    "        if shutil.which(executable):        \n",
    "            print('{} is found'.format(executable))\n",
    "        else:\n",
    "            print('{} is not found'.format(executable))\n",
    "            return newapp\n",
    "    newapp, created = App.objects.get_or_create(name=name)\n",
    "    newapp.name        = name\n",
    "    newapp.executable  = executable\n",
    "    newapp.description = description\n",
    "    newapp.envscript   = envscript\n",
    "    newapp.preprocess  = preprocess\n",
    "    newapp.postprocess = postprocess\n",
    "    newapp.save()\n",
    "    if created: print(\"Created new app\")\n",
    "    else: print(\"Updated existing app\")\n",
    "    return newapp\n",
    "\n",
    "def get_apps(verbose=True):\n",
    "    \"\"\"\n",
    "    Returns all apps as a list\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from balsam.core.models import ApplicationDefinition as App\n",
    "        apps = App.objects.all()\n",
    "    except:\n",
    "        apps = None\n",
    "    return apps\n",
    "        \n",
    "def get_job():\n",
    "    from balsam.launcher.dag import BalsamJob\n",
    "    return BalsamJob()\n",
    "\n",
    "def add_job(name, workflow, application, description='', args='', num_nodes=1, ranks_per_node=1,cpu_affinity='depth',data={},environ_vars={}):\n",
    "    from balsam.launcher.dag import BalsamJob\n",
    "    job                = BalsamJob()\n",
    "    job.name           = name\n",
    "    job.workflow       = workflow\n",
    "    job.application    = application\n",
    "    job.description    = description\n",
    "    job.args           = args\n",
    "    job.num_nodes      = num_nodes\n",
    "    job.ranks_per_node = ranks_per_node\n",
    "    job.cpu_affinity   = cpu_affinity\n",
    "    job.environ_vars   = environ_vars\n",
    "    job.data           = {}\n",
    "    job.save()\n",
    "    \n",
    "def submit(project='datascience',queue='debug-flat-quad',nodes=1,wall_minutes=30,job_mode='mpi',wf_filter=''):\n",
    "    \"\"\"\n",
    "    Submits a job to the queue with the given parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    project: str, name of the project to be charged\n",
    "    queue: str, queue name, can be: 'default', 'debug-cache-quad', or 'debug-flat-quad'\n",
    "    nodes: int, Number of nodes, can be any integer from 1 to 4096.\n",
    "    wall_minutes: int, max wall time in minutes\n",
    "    job_mode: str, Balsam job mode, can be 'mpi', 'serial'\n",
    "    wf_filter: str, Selects Balsam jobs that matches the given workflow filter.\n",
    "    \"\"\"\n",
    "    from balsam import setup\n",
    "    setup()\n",
    "    from balsam.service import service\n",
    "    from balsam.core import models\n",
    "    QueuedLaunch = models.QueuedLaunch\n",
    "    mylaunch = QueuedLaunch()\n",
    "    mylaunch.project = project\n",
    "    mylaunch.queue = queue\n",
    "    mylaunch.nodes = nodes\n",
    "    mylaunch.wall_minutes = wall_minutes\n",
    "    mylaunch.job_mode = job_mode\n",
    "    mylaunch.wf_filter = wf_filter\n",
    "    mylaunch.prescheduled_only=False\n",
    "    mylaunch.save()\n",
    "    service.submit_qlaunch(mylaunch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lus/theta-fs0/projects/connectomics_aesp/balsam_database/\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"BALSAM_DB_PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APP DATABASE\n",
    "## No need to edit those. We will keep then up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new app\n",
      "Created new app\n",
      "Created new app\n",
      "Created new app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Application 8:\n",
       "-----------------------\n",
       "name:                           trakem2_export\n",
       "description:                    TRAKEM2 MPI export script\n",
       "executable:                     python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/mpi_export.py\n",
       "preprocess:                     \n",
       "envscript:                      /lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh\n",
       "postprocess:                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TRAKEM2 APPS\n",
    "\n",
    "##phasing out to be a single function inside the montage job\n",
    "##can be run on a single stupid node\n",
    "# add_app(name='trakem2_pre_tiles',\n",
    "#         executable='python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/preprocess_tiles.py',\n",
    "#         description='TRAKEM2 Create Montage script',\n",
    "#         envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "\n",
    "preamble = ''' babababa '''\n",
    "\n",
    "##need 1 job / node\n",
    "add_app(name='trakem_montage',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/mpi_montage.py',\n",
    "        description='TRAKEM2 MPI montage script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "##can be run on a single stupid node\n",
    "add_app(name='trakem2_proc_folder',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/preprocess_stack.py',\n",
    "        description='TRAKEM2 create pre aligment script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "##need 1 job / node\n",
    "add_app(name='trakem2_align',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/align.py',\n",
    "        description='TRAKEM2 aligment script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "##need 1 job / node\n",
    "add_app(name='trakem2_export',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/software/klab_utils/trakem2/mpi_export.py',\n",
    "        description='TRAKEM2 MPI export script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-c39239ed6af1>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-c39239ed6af1>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    NODES=$COBALT_JOBSIZE\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##ALIGNTK APPS \n",
    "\n",
    "##TODO jobalize the layers bellow\n",
    "\n",
    "#!/bin/bash\n",
    "#COBALT -t 180\n",
    "#COBALT -n 128\n",
    "#COBALT -q default\n",
    "#COBALT -A connectomics_aesp\n",
    "\n",
    "NODES=$COBALT_JOBSIZE\n",
    "PROC_PER_NODE=64\n",
    "PROC=$((NODES * PROC_PER_NODE))\n",
    "#PROC=777\n",
    "\n",
    "ALIGNTK_DIR=/projects/connectomics_aesp/software/aligntk-1.0.2/install/bin\n",
    "IMAGE_DIR=\"../data/images_corr_v2/\"\n",
    "MASK_DIR=\"../masks_corr_v3/\"\n",
    "OUTPUT_DIR=\"./outputs_v1\"\n",
    "GROUP_SIZE=$((PROC-1))\n",
    "N_IMAGES=`ls $IMAGE_DIR | wc -l`\n",
    "N_GROUPS=$((N_IMAGES / GROUP_SIZE + 1))\n",
    "#GROUPS=`seq 0 $((N_GROUPS - 1))`\n",
    "\n",
    "echo \"Total image count: $N_IMAGES\"\n",
    "echo \"Number of groups: $N_GROUPS\"\n",
    "\n",
    "mkdir -p logs\n",
    "mkdir -p $MASK_DIR\n",
    "mkdir -p $OUTPUT_DIR/cmaps\n",
    "mkdir -p $OUTPUT_DIR/logs\n",
    "mkdir -p $OUTPUT_DIR/amaps\n",
    "mkdir -p $OUTPUT_DIR/grids\n",
    "mkdir -p $OUTPUT_DIR/maps\n",
    "mkdir -p $OUTPUT_DIR/aligned\n",
    "\n",
    "def make_schedule:\n",
    "\n",
    "    fprint \"10   1.0  0.1\n",
    "     9   1.0  0.1\n",
    "     8   1.0  0.3\n",
    "     7   1.0  1.0\n",
    "     7   1.0  2.0\n",
    "     7   1.0  5.0\n",
    "     6   1.0  5.0\" > schedule.lst\n",
    "\n",
    "module load miniconda-3.6/conda-4.5.4\n",
    "source activate ~/workspace/envs/py36\n",
    "\n",
    "\n",
    "## preprocess\n",
    "#aligntk_preprocess --image_dir $IMAGE_DIR --output_dir . --group_size $GROUP_SIZE\n",
    "#aprun -n 777 -N $PROC_PER_NODE python -m klab_utils.aligntk_gen_mask --image_dir $IMAGE_DIR --mask_dir $MASK_DIR --low 10 --high 240 --kernel 10\n",
    "\n",
    "## find rst\n",
    "#for (( i=0; i<$N_GROUPS; i++ ))\n",
    "#do\n",
    "#  echo \"find_rst: $i\"\n",
    "#  START=`date +\"%s\"`\n",
    "#  aprun -n $PROC -N $PROC_PER_NODE $ALIGNTK_DIR/find_rst -pairs pairs$i.lst -tif -images $IMAGE_DIR -mask $MASK_DIR -output $OUTPUT_DIR/cmaps/ -rotation -15-15 -max_res 8192 -scale 0.8-1.2 -tx -30-30 -ty -30-30 -summary $OUTPUT_DIR/cmaps/summary$i.out\n",
    "#\tNOW=`date +\"%s\"`\n",
    "#\techo $(((NOW - START)/60)) minutes\n",
    "#done\n",
    "#\n",
    "## register\n",
    "#for (( i=0; i<$N_GROUPS; i++ ))\n",
    "#do\n",
    "#  echo \"register: $i\"\n",
    "#  START=`date +\"%s\"`\n",
    "#  aprun -n $PROC -N $PROC_PER_NODE $ALIGNTK_DIR/register -pairs pairs$i.lst -images $IMAGE_DIR -mask $MASK_DIR -tif -output $OUTPUT_DIR/maps/ -distortion 6.0 -output_level 6 -depth 6 -quality 0.5 -summary $OUTPUT_DIR/maps/summary$i.out -initial_map $OUTPUT_DIR/cmaps/\n",
    "#\tNOW=`date +\"%s\"`\n",
    "#\techo $(((NOW - START)/60)) minutes\n",
    "#done\n",
    "\n",
    "#echo \"register\"\n",
    "#START=`date +\"%s\"`\n",
    "#aprun -n $PROC -N $PROC_PER_NODE $ALIGNTK_DIR/register -pairs pairs.lst -images $IMAGE_DIR -mask $MASK_DIR -tif -output $OUTPUT_DIR/maps/ -distortion 4.0 -output_level 6 -depth 6 -quality 0.3 -summary $OUTPUT_DIR/maps/summary.out -initial_map $OUTPUT_DIR/cmaps/\n",
    "#NOW=`date +\"%s\"`\n",
    "\n",
    "## align\n",
    "#FIXED=`head images.lst -n 1`\n",
    "echo \"align\"\n",
    "START=`date +\"%s\"`\n",
    "aprun -n 8192 -N 64 $ALIGNTK_DIR/align -images $IMAGE_DIR -image_list images.lst -map_list pairs.lst -maps $OUTPUT_DIR/maps/ -masks $MASK_DIR -output $OUTPUT_DIR/amaps/ -schedule schedule.lst -incremental -output_grid $OUTPUT_DIR/grids/ -grid_size 8192x8192 -fold_recovery 60\n",
    "#aprun -n $PROC -N $PROC_PER_NODE $ALIGNTK_DIR/align -images $IMAGE_DIR -image_list images.lst -map_list pairs.lst -masks $MASK_DIR -maps $OUTPUT_DIR/maps/ -output $OUTPUT_DIR/amaps/ -schedule schedule.lst -incremental -output_grid $OUTPUT_DIR/grids/ -grid_size 8192x8192 -fold_recovery 60\n",
    "NOW=`date +\"%s\"`\n",
    "echo $(((NOW - START)/60)) minutes\n",
    "\n",
    "\n",
    "add_app(name='aligntk_apply_map',\n",
    "        executable='python -m klab_utils.aligntk_mpi_apply_map',\n",
    "        description='Distributed FFN training script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "\n",
    "#START=`date +\"%s\"`\n",
    "##$ALIGNTK_DIR/apply_map -image_list images.lst -images $IMAGE_DIR -maps $OUTPUT_DIR/amaps/ -output $OUTPUT_DIR/aligned/ -memory 150000\n",
    "#aprun -n 777 -N 64 python -m klab_utils.aligntk_mpi_apply_map ./outputs_v1/ --image_dir ../data/images_corr_v2/ --image_lst ./images.lst\n",
    "#\n",
    "#NOW=`date +\"%s\"`\n",
    "#echo $(((NOW - START)/60)) minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##U-NET APPS\n",
    "\n",
    "#add_app(name='unet_train')\n",
    "\n",
    "#add_app(name='unet_infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FLORIN APPS\n",
    "\n",
    "#add_app(name='florin_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLOUDVOLUME APPS\n",
    "\n",
    "#add_app(name='cv_create_layer',\n",
    "## --data_path --layer_type --mags --resolution --offset \n",
    "\n",
    "#add_app(name='cv_extract_block')\n",
    "## --info --mag --offset --volume --file --key\n",
    "\n",
    "#add_app(name='get_layer_properties')\n",
    "##--histogram\n",
    "\n",
    "#add_app(name='classify_objects')\n",
    "\n",
    "\n",
    "#add_app(name='cv_create_mesh',\n",
    "\n",
    "#add_app(name='cv_create_skeleton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##AUTOMO APPS\n",
    "\n",
    "#add_app(name='automo_preview',\n",
    "\n",
    "#add_app(name='automo_center',\n",
    "\n",
    "#add_app(name='automo_search_center',\n",
    "\n",
    "#add_app(name='automo_recon',\n",
    "\n",
    "#add_app(name='automo_preview_recon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated existing app\n",
      "Created new app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Application 9:\n",
       "-----------------------\n",
       "name:                           ffn_inference2\n",
       "description:                    FFN inference script\n",
       "executable:                     python /lus/theta-fs0/projects/connectomics_aesp/ffn/run_inference.py\n",
       "preprocess:                     \n",
       "envscript:                      /lus/theta-fs0/projects/connectomics_aesp/balsam/training_env.sh\n",
       "postprocess:                    "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add_app(name='ffn_build_coordinates',\n",
    "\n",
    "#add_app(name='ffn_potato2',\n",
    "\n",
    "\n",
    "add_app(name='ffn_trainer',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/software/ffn/train_hvd.py',\n",
    "        description='Distributed FFN training script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/software/macros_theta/theta_balsam_preamble.sh')\n",
    "\n",
    "add_app(name='ffn_inference2',\n",
    "        executable='python /lus/theta-fs0/projects/connectomics_aesp/ffn/run_inference.py',\n",
    "        description='FFN inference script',\n",
    "        envscript='/lus/theta-fs0/projects/connectomics_aesp/balsam/training_env.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAKEM2 PREAMBLE AND JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAW_INPUT=./trakem2_HL00732\n",
    "PROCESS_FOLDER=./trakem2_HL00732_process_3\n",
    "MIN=1024\n",
    "MAX=2048\n",
    "RANGE=100\n",
    "\n",
    "\n",
    "python $PRE_TILES $RAW_INPUT $PROCESS_FOLDER/align_raw.txt \n",
    "\n",
    "def sem_montage_job(workflow_name, folders):\n",
    "    for kfolder in folders:\n",
    "        \n",
    "        montage_args = ''\n",
    "        montage_args += f' $PROCESS_FOLDER/align_raw.txt '\n",
    "        montage_args += f' $PROCESS_FOLDER '\n",
    "        montage_args += f' --min $MIN '\n",
    "        montage_args += f' --max $MAX '\n",
    "        montage_args += f' --fiji $FIJI '\n",
    "        print(montage_args)\n",
    "\n",
    "        add_job(name=f'montage',\n",
    "            workflow=workflow_name,\n",
    "            data={folder}\n",
    "            application='trakem2_montage',\n",
    "            args=montage_args,\n",
    "            ranks_per_node=1,\n",
    "            environ_vars='OMP_NUM_THREADS=32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# python $PRE_STACK $PROCESS_FOLDER/output $PROCESS_FOLDER/align_new.txt #input #output\n",
    "\n",
    "#SERIAL SINGLE NODE OPERATION!!!\n",
    "# $SUBMIT_THETA python $ALIGN $PROCESS_FOLDER/align_new.txt $PROCESS_FOLDER/align1 --fiji $FIJI\n",
    "\n",
    "#$SUBMIT_THETA python $EXPORT $PROCESS_FOLDER/align_new.txt $PROCESS_FOLDER/align1 --range $RANGE --fiji $FIJI\n",
    "sleep 1\n",
    "\n",
    "\n",
    "add_job(name='test_train',workflow='ffn_training',application='trainer',args=myargs)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLOOD FILL NETWORK PREAMBLE AND JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/gpfs/mira-home/keceli/ffn/keceli_ffn/')\n",
    "sys.path.insert(0,'/lus/theta-fs0/projects/connectomics_aesp/keceli/pip_ffn/')\n",
    "sys.path.insert(0,'/soft/datascience/tensorflow/tf1.13/')\n",
    "\n",
    "from ffn.utils import bounding_box\n",
    "from ffn.utils import geom_utils\n",
    "\n",
    "def create_inference_config(pars, file_name):\n",
    "    request_par = ('''image {\n",
    "                  hdf5: \"%s:%s\"\n",
    "                }\n",
    "                image_mean: %s\n",
    "                image_stddev: %s\n",
    "                checkpoint_interval: 1800\n",
    "                seed_policy: \"PolicyPeaks\"\n",
    "                model_checkpoint_path: \"%s\"\n",
    "                model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "                model_args: \"{\\\\\"depth\\\\\": 2, \\\\\"fov_size\\\\\": [5,5,5], \\\\\"deltas\\\\\": [1, 1, 1]}\"\n",
    "                segmentation_output_dir: \"%s\"\n",
    "                inference_options {\n",
    "                  init_activation: 0.9\n",
    "                  pad_value: 0.05\n",
    "                  move_threshold: 0.1\n",
    "                  min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "                  segment_threshold: 0.08\n",
    "                  min_segment_size: 10\n",
    "                }''') % pars\n",
    "    print (request_par)\n",
    "\n",
    "def divide_bounding_box(bbox, subvolume_size, overlap):\n",
    "    \"\"\"\n",
    "    Returns a list of bounding boxes that divides the given bounding box into subvolumes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox: BoundingBox object,\n",
    "    subvolume_size: list or tuple\n",
    "    overlap: list or tuple\n",
    "    \"\"\"\n",
    "    start = geom_utils.ToNumpy3Vector(bbox.start)\n",
    "    size = geom_utils.ToNumpy3Vector(bbox.size)\n",
    "    bbox = bounding_box.BoundingBox(start, size)\n",
    "    calc = bounding_box.OrderlyOverlappingCalculator(outer_box=bbox, \n",
    "                                                    sub_box_size=subvolume_size, \n",
    "                                                    overlap=overlap, \n",
    "                                                    include_small_sub_boxes=True,\n",
    "                                                    back_shift_small_sub_boxes=False)\n",
    "    return [bb for bb in calc.generate_sub_boxes()]\n",
    "\n",
    "def check_balsam_jobs(bbox, config_file):\n",
    "    for i,box in enumerate(boxes):\n",
    "        start = box.start\n",
    "        size  = box.size\n",
    "        print(f\" --bounding_box 'start {{ x:{start[0]} y:{start[1]} z:{start[2]} }} size {{ x:{size[0]} y:{size[1]} z:{size[2]} }}' \")\n",
    "    print(f\" --inference_request=\\\"$(cat \"+config_file+\")\\\" \")\n",
    "\n",
    "\n",
    "def generate_balsam_inference_jobs(bbox_list, config_file, workflow_name='ffn_sub_inference'):\n",
    "    for i,box in enumerate(bbox_list):\n",
    "        start = box.start\n",
    "        size  = box.size\n",
    "        inference_args  = f\" --inference_request=\\\"$(cat \"+config_file+\")\\\" \"\n",
    "        inference_args += f\" --bounding_box 'start {{ x:{start[0]} y:{start[1]} z:{start[2]} }} size {{ x:{size[0]} y:{size[1]} z:{size[2]} }}' \"\n",
    "        add_job(name=f'sub_inference_{i}',\n",
    "                workflow=workflow_name,\n",
    "                application='inference2',\n",
    "                args=inference_args,\n",
    "                ranks_per_node=1,\n",
    "                environ_vars='OMP_NUM_THREADS=32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Fill Network Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --train_coords /lus/theta-fs0/projects/datascience/keceli/run/f3n/training/tf_record_file  --data_volumes valdation1:/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/grayscale_maps.h5:raw  --label_volumes valdation1:/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/groundtruth.h5:stack  --model_name convstack_3d.ConvStack3DFFNModel  --model_args \"{\\\"depth\\\": 12, \\\"fov_size\\\": [33, 33, 33], \\\"deltas\\\": [8, 8, 8]}\" --image_mean 128 --image_stddev 33  --max_steps 400 --summary_rate_secs 60  --batch_size 1  --optimizer adam  --num_intra_threads 64 --num_inter_threads 1  --train_dir train_b1_oadam_191001210138 \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "TFRECORDFILE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/tf_record_file'\n",
    "GROUNDTRUTH='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/groundtruth.h5'\n",
    "GRAYSCALE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/grayscale_maps.h5'\n",
    "BATCHSIZE=1\n",
    "OPTIMIZER='adam'\n",
    "TIMESTAMP=time.strftime(\"%y%m%d%H%M%S\")\n",
    "TRAINDIR=f'train_b{BATCHSIZE}_o{OPTIMIZER}_{TIMESTAMP}'\n",
    "\n",
    "myargs = ''\n",
    "myargs += f' --train_coords {TFRECORDFILE} '\n",
    "myargs += f' --data_volumes valdation1:{GRAYSCALE}:raw '\n",
    "myargs += f' --label_volumes valdation1:{GROUNDTRUTH}:stack '\n",
    "myargs += f' --model_name convstack_3d.ConvStack3DFFNModel '\n",
    "myargs += ''' --model_args \"{\\\\\"depth\\\\\": 12, \\\\\"fov_size\\\\\": [33, 33, 33], \\\\\"deltas\\\\\": [8, 8, 8]}\"'''\n",
    "myargs += ' --image_mean 128 --image_stddev 33 '\n",
    "myargs += ' --max_steps 400 --summary_rate_secs 60 ' \n",
    "myargs += f' --batch_size {BATCHSIZE} '\n",
    "myargs += f' --optimizer {OPTIMIZER} '\n",
    "myargs += ' --num_intra_threads 64 --num_inter_threads 1 '\n",
    "myargs += f' --train_dir {TRAINDIR} '\n",
    "print(myargs)\n",
    "\n",
    "add_job(name='test_train',workflow='ffn_training',application='trainer',args=myargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Fill Network Inference Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image {\n",
      "                  hdf5: \"input_file_parallel.h5:image\"\n",
      "                }\n",
      "                image_mean: 100\n",
      "                image_stddev: 30\n",
      "                checkpoint_interval: 1800\n",
      "                seed_policy: \"PolicyPeaks\"\n",
      "                model_checkpoint_path: \"model_vessel/model.ckpt-1680104\"\n",
      "                model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
      "                model_args: \"{\\\"depth\\\": 2, \\\"fov_size\\\": [5,5,5], \\\"deltas\\\": [1, 1, 1]}\"\n",
      "                segmentation_output_dir: \"results_test_parallel6\"\n",
      "                inference_options {\n",
      "                  init_activation: 0.9\n",
      "                  pad_value: 0.05\n",
      "                  move_threshold: 0.1\n",
      "                  min_boundary_dist { x: 1 y: 1 z: 1}\n",
      "                  segment_threshold: 0.08\n",
      "                  min_segment_size: 10\n",
      "                }\n",
      "Number of subvolumes: 125\n"
     ]
    }
   ],
   "source": [
    "# Add inference jobs for each subvolume\n",
    "\n",
    "\n",
    "INPUT_FILE = 'input_file_parallel.h5'\n",
    "INPUT_DSET = 'image'\n",
    "OUTPUT_FILE = 'output_file_parallel.h5'\n",
    "OUTPUT_DSET = 'image'\n",
    "OUTPUT_PATH = 'results_test_parallel6'\n",
    "MEAN = 100\n",
    "STD = 30\n",
    "MODEL_PATH = 'model_vessel/model.ckpt-1680104'\n",
    "DEPTH = 2\n",
    "START = (0,0,0)\n",
    "SIZE = (1000,1000,1000)\n",
    "CHUNK_SIZE = (256,256,256)\n",
    "OVERLAP = (16,16,16)\n",
    "\n",
    "bbox = bounding_box.BoundingBox(start=START,size=SIZE)\n",
    "pars =  (INPUT_FILE,INPUT_DSET, MEAN, STD, MODEL_PATH, OUTPUT_PATH)\n",
    "\n",
    "test = create_inference_config(pars, 'test')\n",
    "config_file = '/lus/theta-fs0/projects/connectomics_aesp/ravescovi/ffn_vessels_overlay_sean_anno/wholebrain.pbtxt'\n",
    "\n",
    "boxes = divide_bounding_box(bbox,subvolume_size=CHUNK_SIZE,overlap=OVERLAP)\n",
    "print(f'Number of subvolumes: {len(boxes)}')\n",
    "\n",
    "generate_balsam_inference_jobs(boxes, config_file, workflow_name='inference_8_8_v8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f187ed14b38>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Balsam metadata\n",
    "from balsam.core.models import utilization_report, throughput_report, process_job_times, BalsamJob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "workflow = \"inference_8_8_v8\"\n",
    "\n",
    "##useful shit\n",
    "query = BalsamJob.objects.filter(workflow=workflow)\n",
    "time_dat = process_job_times(query) #filters into a single workflow\n",
    "[j.runtime_seconds for j in query] # full time per balsam Job\n",
    "\n",
    "times_created, num_created = sorted(time_dat['CREATED']), range(1, len(time_dat[\"CREATED\"])+1)\n",
    "\n",
    "t0 = min(times_created)\n",
    "\n",
    "def mins(t):\n",
    "    return (t-t0).total_seconds() / 60\n",
    "\n",
    "plt.step([mins(t) for t in times_created] ,num_created, 'o', where='post',label='creation')\n",
    "times, num_thru = throughput_report(time_dat)\n",
    "plt.step([mins(t) for t in times], num_thru,  'o', where='post', label='done')\n",
    "\n",
    "times_u, num_util = utilization_report(time_dat)\n",
    "plt.step([mins(t) for t in times_u], num_util, 'o', where='post', label='utilization')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Fill Network MultScale Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiscale training job\n",
    "TFRECORDFILE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/tf_record_file'\n",
    "GROUNDTRUTH='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/groundtruth.h5'\n",
    "GRAYSCALE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/grayscale_maps.h5'\n",
    "BATCHSIZE=1\n",
    "OPTIMIZER='adam'\n",
    "\n",
    "MAGS = [1,2,4,8,16]\n",
    "\n",
    "for mag in MAGS:\n",
    "    \n",
    "    \n",
    "for mag in MAGS:    \n",
    "    TRAINDIR=f'train_b{BATCHSIZE}_o{OPTIMIZER}_m{mag}_{TIMESTAMP}'\n",
    "    myargs = ''\n",
    "    myargs += f' --train_coords {TFRECORDFILE} '\n",
    "    myargs += f' --data_volumes valdation1:{GRAYSCALE}:raw '\n",
    "    myargs += f' --label_volumes valdation1:{GROUNDTRUTH}:stack '\n",
    "    myargs += f' --model_name convstack_3d.ConvStack3DFFNModel '\n",
    "    myargs += ''' --model_args \"{\\\\\"depth\\\\\": 12, \\\\\"fov_size\\\\\": [33, 33, 33], \\\\\"deltas\\\\\": [8, 8, 8]}\"'''\n",
    "    myargs += ' --image_mean 128 --image_stddev 33 '\n",
    "    myargs += ' --max_steps 40000000 --summary_rate_secs 360 ' \n",
    "    myargs += f' --batch_size {BATCHSIZE} '\n",
    "    myargs += f' --optimizer {OPTIMIZER} '\n",
    "    myargs += ' --num_intra_threads 64 --num_inter_threads 1 '\n",
    "    myargs += f' --train_dir {TRAINDIR} '\n",
    "\n",
    "    add_job(name=f'train_mag{mag}',\n",
    "            workflow='ffn_training',\n",
    "            application='trainer',\n",
    "            args=myargs,\n",
    "            ranks_per_node=rpn,\n",
    "            num_nodes=nnode,\n",
    "            environ_vars={'OMP_NUM_THREADS=64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Space Bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a training job to the database\n",
    "import time\n",
    "TFRECORDFILE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/tf_record_file'\n",
    "GROUNDTRUTH='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/groundtruth.h5'\n",
    "GRAYSCALE='/lus/theta-fs0/projects/datascience/keceli/run/f3n/training/grayscale_maps.h5'\n",
    "BATCHSIZE=1\n",
    "OPTIMIZER='adam'\n",
    "TIMESTAMP=time.strftime(\"%y%m%d%H%M%S\")\n",
    "for rpn in [1,4,16]:\n",
    "    for nnode in [1,4,16,64]:\n",
    "        TRAINDIR=f'train_b{BATCHSIZE}_o{OPTIMIZER}_n{nnode}_r{rpn}_{TIMESTAMP}'\n",
    "        myargs = ''\n",
    "        myargs += f' --train_coords {TFRECORDFILE} '\n",
    "        myargs += f' --data_volumes valdation1:{GRAYSCALE}:raw '\n",
    "        myargs += f' --label_volumes valdation1:{GROUNDTRUTH}:stack '\n",
    "        myargs += f' --model_name convstack_3d.ConvStack3DFFNModel '\n",
    "        myargs += ''' --model_args \"{\\\\\"depth\\\\\": 12, \\\\\"fov_size\\\\\": [33, 33, 33], \\\\\"deltas\\\\\": [8, 8, 8]}\"'''\n",
    "        myargs += ' --image_mean 128 --image_stddev 33 '\n",
    "        myargs += ' --max_steps 40000000 --summary_rate_secs 360 ' \n",
    "        myargs += f' --batch_size {BATCHSIZE} '\n",
    "        myargs += f' --optimizer {OPTIMIZER} '\n",
    "        myargs += ' --num_intra_threads 64 --num_inter_threads 1 '\n",
    "        myargs += f' --train_dir {TRAINDIR} '\n",
    "\n",
    "        add_job(name=f'train_n{nnode}_r{rpn}',\n",
    "                workflow='ffn_training',\n",
    "                application='trainer',\n",
    "                args=myargs,\n",
    "                ranks_per_node=rpn,\n",
    "                num_nodes=nnode,\n",
    "                environ_vars={'OMP_NUM_THREADS=64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit OK: Qlaunch {   'command': '/lus/theta-fs0/projects/connectomics_aesp/balsam_database/qsubmit/qlaunch51.sh',\n",
      "    'from_balsam': True,\n",
      "    'id': 51,\n",
      "    'job_mode': 'mpi',\n",
      "    'nodes': 128,\n",
      "    'prescheduled_only': False,\n",
      "    'project': 'SDL_workshop',\n",
      "    'queue': 'training',\n",
      "    'scheduler_id': 374843,\n",
      "    'state': 'submitted',\n",
      "    'wall_minutes': 40,\n",
      "    'wf_filter': 'inference_8_8_v8'}\n"
     ]
    }
   ],
   "source": [
    "# If you see 'Submit OK:', Job submission is succesful.\n",
    "submit(project='SDL_workshop',\n",
    "       queue='training',\n",
    "       nodes=128,\n",
    "       wall_minutes=40,\n",
    "       wf_filter='inference_8_8_v8')\n",
    "\n",
    "# submit(project='connectomics_aesp',\n",
    "#        queue='default',\n",
    "#        job_mode='serial',\n",
    "#        nodes=128,\n",
    "#        wall_minutes=180,\n",
    "#        wf_filter='inference_8_8')\n",
    "\n",
    "# submit(project='connectomics_aesp',\n",
    "#        queue='debug-flat-quad',\n",
    "#        nodes=3,\n",
    "#        wall_minutes=59,\n",
    "#        wf_filter='ffn_sub_inference')\n",
    "\n",
    "# submit(project='connectomics_aesp',\n",
    "#        queue='default',\n",
    "#        nodes=256,\n",
    "#        wall_minutes=359,\n",
    "#        wf_filter='ffn_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
